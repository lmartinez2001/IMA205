{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIxyPJX28-WQ"
      },
      "source": [
        "**Emotion Recognition based on facial landmarks**\n",
        "\n",
        "This part of the practical session is about **emotion recognition** based on facial landmarks. We will use the FEI dataset (https://fei.edu.br/~cet/facedatabase.html) to recognize the emotion of a person by analyzing 68 facial landmarks (already estimated and placed). Below, you will find a picture with an example. We will focus on two emotions neutral and happy.\n",
        "\n",
        "Please answer all questions and complete the code where you see **XXXXXXXXXXXXX**\n",
        "\n",
        "**Deadline**: Upload this notebook, the one about Toy Examples and the answers to the theoretical questions to E-Campus. Please verify the exact deadline on E-Campus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSR4ZvCdadtc"
      },
      "source": [
        "First of all, we need to load the data. In Google Colab, we can load from Google Drive or from our local machine. Since it's faster from Google Drive, let's load them from (my) Google Drive, using the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPwLc8FAYwx1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id='15vsAdMepHzdoZ3iqNS3kpI3KGW7D0vRs',\n",
        "  dest_path='./Data_FEI.npz')\n",
        "  gdd.download_file_from_google_drive(file_id='1ywQbf23-JoPklWCcH_mi5Nuw5BQskxvB',\n",
        "  dest_path='./facial_landmarks_68markup.jpg')\n",
        "else:\n",
        "  print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data')\n",
        "\n",
        "# Please modify working_dir only if you are using your Anaconda (and not Google Colab)\n",
        "# You should write the absolute path of your working directory with the data\n",
        "Working_directory=\"./\"    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyTzYCOzaZTR"
      },
      "source": [
        "Otherwise, you can also load them from your local machine using the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHIg_hcbWnSA"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\"\"\"      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6mqjezj8Xwo"
      },
      "source": [
        "Let's load the Python packages containing the functions needed for the practical session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqyKgh23Z_-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import paired_distances\n",
        "from sklearn.model_selection import  cross_val_score, cross_validate, GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import decomposition\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "# this is needed to plot figures within the notebook\n",
        "%matplotlib inline \n",
        "np.random.seed(seed=666)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCRirMCm_sXL"
      },
      "source": [
        "We also load a user-defined function useful for plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBbjM7ISbCxH"
      },
      "outputs": [],
      "source": [
        "# Code from scikit-learn\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    \n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]), \n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "    \n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "            rotation_mode=\"anchor\")\n",
        "  \n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOZakxnq_J6u"
      },
      "source": [
        "Now, let's load the data. \n",
        "\n",
        "We have a list of images, the position of the original landmarks (aligned to the images), the position of the landmarks after a normalization process called Generalized Procrustes Analysis (please refer to https://en.wikipedia.org/wiki/Generalized_Procrustes_analysis), the outputs with the class labels and the names of the images.\n",
        "\n",
        "Generalized Procrustes Analysis (GPA) is used to keep only shape differences between the configurations of landmarks. That is to say, we align all configurations to an average one using only rigid transformations (uniform scaling, rotation and translation). This means that if I take a facial picture of subject A, then step back, translate and rotate a bit the camera and retake a facial picture of the same subject (who has not moved) the two picture will be different with therefore different landmark position. However, after a GPA, the two landmark configurations should be perfectly aligned removing the \"nuisance\" differences related to rotation, translation and uniform scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR5AG32zaFJO"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "dim=2 # dimension   \n",
        "# Loading data\n",
        "with np.load(Working_directory + 'Data_FEI.npz') as data:\n",
        "    Images=data['Images_FEI'] # list of images\n",
        "    X = data['Landmarks_FEI'] # original landmarks   \n",
        "    XGPA = data['Landmarks_FEI_GPA'] # landmarks after GPA (Generalized Procrustes Analysis, https://en.wikipedia.org/wiki/Generalized_Procrustes_analysis)\n",
        "    Y = data['Emotions_FEI'] # class, 0 for neutral and 1 for happy\n",
        "    Names = data['Names_FEI']    \n",
        "N,M = X.shape # number subjects \n",
        "M = int(M/2) # Number of landmarks (they are in 2D)\n",
        "print('Number of subjects:', N, '; Number of landmarks:',M) \n",
        "class_names = [\"neutral\",\"happy\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDTPtOe3_S9q"
      },
      "source": [
        "Here, we show an example of facial landmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdwR8vMObE2U"
      },
      "outputs": [],
      "source": [
        "# Plot the facial landmarks\n",
        "Example=plt.imread(Working_directory + './facial_landmarks_68markup.jpg') # function to read a jpg image\n",
        "plt.figure(figsize = (8,8)) # Size of the plot\n",
        "plt.imshow(Example)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaDQ2y8E-5zm"
      },
      "outputs": [],
      "source": [
        "# plot the first 6 images of the data-set\n",
        "for i in range(0,6):\n",
        "    image = Images[i,:,:]\n",
        "    plt.figure()\n",
        "    plt.imshow(image, cmap='gray', origin='upper')\n",
        "    landmark=X[i,:]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    plt.plot(x,y,'o')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24oc0rHICDn9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Question**: after plotting the first 6 images of the data-set, what do you notice ? Do you notice a regular pattern ? Do you think that it would be worth it to randomly shuffle the data ?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_r20-_8bJyP"
      },
      "outputs": [],
      "source": [
        "# Shuffle data randomly. Hint: Use np.random.shuffle\n",
        "indeces=XXXXXXXXXXX\n",
        "\n",
        "XpGPA=XGPA[indeces]\n",
        "Xp=X[indeces]\n",
        "Yp=Y[indeces]\n",
        "Imagesp=Images[indeces]\n",
        "Xmean = np.mean(XpGPA,axis=0) # Compute average\n",
        "\n",
        "Namesp=[''] * N\n",
        "for i in range(0,N):\n",
        "    Namesp[i]=Names[indeces[i]]   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVLx73WeA0Ye"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Among the loaded data, we also have aligned landmarks after a Generalized Procrustes Analysis. Let's check them and compare them with the landmarks before alignement.\n",
        "\n",
        "\n",
        "**QUESTION**: Please comment the results. What can you notice ?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV2ITuDFBIJ4"
      },
      "outputs": [],
      "source": [
        "# Plot all landmarks BEFORE GPA\n",
        "plt.figure()\n",
        "for i in range(0,N):\n",
        "    landmark=Xp[i]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    if Yp[i].astype(int)==0:\n",
        "        neutral=plt.scatter(x, y, c='b')\n",
        "    else:\n",
        "        happy=plt.scatter(x, y, c='r')\n",
        "Xaverage = np.mean(Xp,axis=0) # Compute average\n",
        "average=plt.scatter(Xaverage[::2],Xaverage[1::2],color='k')            \n",
        "plt.legend((neutral,happy,average),('neutral','happy','average'))\n",
        "plt.gca().invert_yaxis() \n",
        "plt.title('Landmarks BEFORE alignement (GPA)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBqQTU0UbOfT"
      },
      "outputs": [],
      "source": [
        "# Plot all landmarks AFTER GPA\n",
        "plt.figure()\n",
        "for i in range(0,N):\n",
        "    landmark=XpGPA[i]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    if Yp[i].astype(int)==0:\n",
        "        neutral=plt.scatter(x, y, c='b')\n",
        "    else:\n",
        "        happy=plt.scatter(x, y, c='r')\n",
        "average=plt.scatter(Xmean[::2],Xmean[1::2],color='k')            \n",
        "plt.legend((neutral,happy,average),('neutral','happy','average'))\n",
        "plt.gca().invert_yaxis()   \n",
        "plt.title('Landmarks AFTER alignement (GPA)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhU9XqnOBunD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We need now to compute some features for the classification algorithms. As first idea, we could use the paired Euclidean distances between the landmarks of every subject and the landmarks of the average configuration. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vda9bvh0bTje"
      },
      "outputs": [],
      "source": [
        "# Compute distances from the average configuration (features)\n",
        "dist_average=np.zeros((N,M))\n",
        "average=np.reshape(Xmean,(M,2)) # Reshape average as matrix\n",
        "\n",
        "for i in range(N):\n",
        "    landmark=XXXXXXXXXXX # Reshape all landmarks as matrices\n",
        "    dist_average[i]=XXXXXXXXXXX  \n",
        "\n",
        "print('Number of subjects N is: ', dist_average.shape[0], ' ; number of features is: ',  dist_average.shape[1] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's divide the data-set into Training and Test sets:"
      ],
      "metadata": {
        "id": "OkQknMkrVH_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(dist_average, np.ravel(Yp), test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "JfL8bT5XVcTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fQnuyeA8-Wo"
      },
      "source": [
        "---\n",
        "\n",
        "**Question**: One usual question in Machine Learning is, do we need to scale/normalize the features ? What do you think ? Should we do it in this case ? Compute both scaled and normalized data.\n",
        "\n",
        "Please note that we compute the parameters of 'StandardScaler()' and 'MinMaxScaler()' using only the training set and then we trasform both the traning and test sets using the parameters learnt only on the training set.\n",
        "\n",
        "**Question**: Why do we do that in your opinion ?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnuByXuy8-Wo"
      },
      "outputs": [],
      "source": [
        "# Scale data (each feature will have average equal to 0 and unit variance)\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scale=scaler.transform(X_train)\n",
        "X_test_scale=scaler.transform(X_test)\n",
        "\n",
        "# Normalize data (each feature will be scaled into the range 0,1)\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmaxscaler#sklearn.preprocessing.MinMaxScaler\n",
        "\n",
        "normalizer = MinMaxScaler()\n",
        "XXXXXXXXXXX\n",
        "X_train_normalize=XXXXXXXXXXX\n",
        "X_test_normalize=XXXXXXXXXXX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTvUCvRqDt_a"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Let's try to fit LDA to all training sets and predict the error on their respective test sets. \n",
        "\n",
        "**Question**: Compare the performnces between original, scaled and normalized data. Comment the results.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3oP_F_6DSGX"
      },
      "outputs": [],
      "source": [
        "# Fitting LDA to original data\n",
        "print(\"Fitting LDA to training set\")\n",
        "t0 = time()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train)\n",
        "y_pred = lda.predict(X_test)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwpX_lT08-Wq"
      },
      "outputs": [],
      "source": [
        "# Fitting LDA to scaled data\n",
        "XXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U2OTHSd8-Wq"
      },
      "outputs": [],
      "source": [
        "# Fitting LDA to normalized data\n",
        "XXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKSdLTs6CLgW"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We can then use the function 'cross_val_score' to compute the CV score. Let's use all methods seen today. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avl_PwWpbcxi"
      },
      "outputs": [],
      "source": [
        "# Cross-validation for Model Assessment\n",
        "\n",
        "# Fitting LDA\n",
        "print(\"Fitting LDA\")\n",
        "t0 = time()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda_score = cross_val_score(lda,X=dist_average, y=np.ravel(Yp),cv=5)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(lda_score.mean(), lda_score.std() ))\n",
        "\n",
        "# Fitting QDA\n",
        "print(\"Fitting QDA\")\n",
        "t0 = time()\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda_score = XXXXXXXXXXX\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(qda_score.mean(), qda_score.std() ))\n",
        "\n",
        "# Fitting Logistic-regression\n",
        "print(\"Fitting Logistic Regression\")\n",
        "t0 = time()\n",
        "logit = LogisticRegression(solver='lbfgs')\n",
        "logit_score = XXXXXXXXXXX\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(logit_score.mean(), logit_score.std() ))\n",
        "\n",
        "# Fitting Naive-Bayes\n",
        "print(\"Fitting Naive-Bayes\")\n",
        "t0 = time()\n",
        "GNB = GaussianNB()\n",
        "GNB_score = XXXXXXXXXXX\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(GNB_score.mean(), GNB_score.std() ))\n",
        "\n",
        "# Fitting K-nearest neighbour\n",
        "print(\"Fitting K-nearest neighbour\")\n",
        "t0 = time()\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh_score = XXXXXXXXXXX\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(neigh_score.mean(), neigh_score.std() ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Question**: compare the performances between original, scaled and normalized data\n",
        "\n",
        "Be careful, if you want to standardize your data within a cross validation it means that you should fit 'StandardScaler()' only to the K-1 training folds without using the K-th test fold ! And then transform all folds.\n",
        "How can we do that ? \n",
        "\n",
        "Scikit-learn gives us a very nice tool: THE PIPELINE ! It makes it easier to chain standardization, normalizations, etc. with estimators during a cross validation. Please have a look here: https://scikit-learn.org/stable/common_pitfalls.html\n",
        "\n",
        "How can we build a Pipeline? It's very simple. Just concatenate the trasformation and the the estimator you want to use:\n",
        "\n",
        "model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Wu6ZusqqXzXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation for Model Assessment with Standaridzation\n",
        "\n",
        "# Fitting LDA\n",
        "print(\"Fitting LDA\")\n",
        "t0 = time()\n",
        "lda = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\n",
        "lda_score = cross_val_score(lda,X=dist_average, y=np.ravel(Yp),cv=5)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\" Average and std CV score : {0} +- {1}\".format(lda_score.mean(), lda_score.std() ))\n",
        "\n",
        "# Fitting QDA\n",
        "XXXXXXXXXXX\n",
        "\n",
        "# Fitting Logistic-regression\n",
        "XXXXXXXXXXX\n",
        "\n",
        "# Fitting Naive-Bayes\n",
        "XXXXXXXXXXX\n",
        "\n",
        "# Fitting K-nearest neighbour\n",
        "XXXXXXXXXXX"
      ],
      "metadata": {
        "id": "LeiQQZHaYE0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZSRkXyNUOoe"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "In the previous example we have fixed the hyper-parameter K to 3. We could use CV to find the best value.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_McIrKvZUcc"
      },
      "outputs": [],
      "source": [
        "# Looking for the best K in K-nearest neighbour\n",
        "parameters = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10]}\n",
        "neighCV = KNeighborsClassifier()\n",
        "grid = GridSearchCV(neighCV, parameters, cv=5, n_jobs=-1)\n",
        "grid.fit(dist_average, np.ravel(Yp))\n",
        "\n",
        "print('The best K is', grid.best_params_.get('n_neighbors'), ' with an average validation score equal to ', grid.best_score_)\n",
        "\n",
        "# plot the CV validation score for each K value\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10], grid.cv_results_.get('mean_test_score'))\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('CV Validation Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfvPPp2dVM_h"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We could also use CV to assess the prediction error (generalization error) in a left-out test set.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aVIfWPOVWDA"
      },
      "outputs": [],
      "source": [
        "# We only use the training set for finding the best hyper-parameter\n",
        "parameters = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10]}\n",
        "neighCV = KNeighborsClassifier()\n",
        "grid = GridSearchCV(neighCV, parameters, cv=5, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print('The best K is', grid.best_params_.get('n_neighbors'), ' with an average validation score equal to ', grid.best_score_)\n",
        "\n",
        "# plot the CV validation score for each K value\n",
        "plt.plot([1,2,3,4,5,6,7,8,9,10], grid.cv_results_.get('mean_test_score'))\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('CV Validation Score')\n",
        "\n",
        "# Let's now use the best model to assess the test score\n",
        "BestModel=grid.best_estimator_\n",
        "print('The test score is', BestModel.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br2UH3eAXL6T"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Question**: Comment the results of the two previosu experiments. What about the best K and validation/test error ? Are the results the same ? Why in your opinion ?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk_0Fg5QKzcp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "It seems that these features do not work very well... let's try to change them.\n",
        "We can use the distances between all combinations of landmarks. Each subject has M*(M-1)/2 features.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKej-3UtK6de"
      },
      "outputs": [],
      "source": [
        "# Use distances between all combinations of landmarks. Each subject has M*(M-1)/2 features\n",
        "dist_combination=np.zeros((N,int((M*(M-1)/2))))\n",
        "XXXXXXXXXXX\n",
        "\n",
        "print('Number of subjects N is: ', dist_combination.shape[0], ' ; number of features is: ',  dist_combination.shape[1] )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train, X2_test, y2_train, y2_test = train_test_split(dist_combination, np.ravel(Yp), test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "j7KlhG3OY5c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eyrp3728-Wv"
      },
      "source": [
        "**Question**: Should we scale/normalize the new features ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb-akJpl8-Wv"
      },
      "source": [
        "Use the classification algorithms seen before to test the discriminative power of the new features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rr7nHm6LBKZ"
      },
      "outputs": [],
      "source": [
        "XXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxXD7FNsLayh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "mmmm it seems that some variables are collinear. Collinearity means that one variable can be linearly predicted by the others, basically it means that there is redundancy. \n",
        "\n",
        "**Question**: Which technique could you use to reduce the collinearity/redundancy ? Use it and test the predictive power of the new features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1ZedfMtLtlK"
      },
      "outputs": [],
      "source": [
        "XXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM1mHhySO5GE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "A second solution, would be to manually select few landmarks\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB2we7yiO9Pa"
      },
      "outputs": [],
      "source": [
        "# Select lateral landmarks mouth\n",
        "select_land=[49,50,60,55,54,56]\n",
        "indeces_central=[]\n",
        "for k in range(0,len(select_land)):\n",
        "    indeces_central.append(select_land[k]*2-2) # Remember that landmarks are M*2 vectors (odds values are the x and even values are the y)\n",
        "    indeces_central.append(select_land[k]*2-1)\n",
        "    \n",
        "indeces_central=np.array(indeces_central,dtype=int)\n",
        "Ms=int(len(indeces_central)/2) \n",
        "Xps=np.zeros((N,Ms*dim))\n",
        "XpsGPA=np.zeros((N,Ms*dim))\n",
        "for i in range(0,N):\n",
        "    XpsGPA[i,:]=XpGPA[i,indeces_central]\n",
        "    Xps[i,:]=Xp[i,indeces_central]\n",
        "    \n",
        "Yps=Yp\n",
        "  \n",
        "print('Number of subjects N is: ', XpsGPA.shape[0], ' ; number of features is: ',  XpsGPA.shape[1] )  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-87Pxg8PFEO"
      },
      "outputs": [],
      "source": [
        "# plot two test images \n",
        "for i in range(0,2):\n",
        "    image = Imagesp[i,:,:]\n",
        "    plt.figure()\n",
        "    plt.imshow(image, cmap='gray', origin='upper')\n",
        "    landmark=Xps[i,:]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    plt.plot(x,y,'o')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlLBo5GEPMSj"
      },
      "outputs": [],
      "source": [
        "# Plot only selected landmarks\n",
        "plt.figure()\n",
        "for i in range(0,N):\n",
        "    landmark=XpsGPA[i]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    if Yps[i].astype(int)==0:\n",
        "        neutral=plt.scatter(x, y, c='b')\n",
        "    else:\n",
        "        happy=plt.scatter(x, y, c='r')\n",
        "        \n",
        "plt.legend((neutral,happy),('neutral','happy'))\n",
        "plt.gca().invert_yaxis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIZP91DLPRtM"
      },
      "outputs": [],
      "source": [
        "# Fitting LDA\n",
        "print(\"Fitting LDA\")\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda_validate = cross_validate(lda,X=XpsGPA, y=np.ravel(Yps), cv=5, n_jobs=-1, return_train_score=True, return_estimator=True )\n",
        "print(\" Average and std train score : {0} +- {1}\".format(lda_validate['train_score'].mean(), lda_validate['train_score'].std() ))\n",
        "print(\" Average and std test score : {0} +- {1}\".format(lda_validate['test_score'].mean(), lda_validate['test_score'].std() ))\n",
        "\n",
        "# Let's look for the best CV model (the one with the best test score)\n",
        "best_estimator=lda_validate['estimator'][np.argmax(lda_validate['test_score'])]\n",
        "C=best_estimator.predict(XpsGPA)\n",
        "\n",
        "# Let's find the images where it did a mistake\n",
        "error=np.ravel(np.array(np.where(np.abs(C-np.ravel(Yps)))))  \n",
        "if len(error)>5:\n",
        "    kk=5\n",
        "else:\n",
        "    kk=len(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klfrmw_H-lh7"
      },
      "source": [
        "---\n",
        "\n",
        "Let's plot some images where the best model was wrong. \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-SdQOwXPTdu"
      },
      "outputs": [],
      "source": [
        "# plot error images\n",
        "for i in range(0,kk):\n",
        "    image = Imagesp[error[i],:,:]\n",
        "    plt.figure()\n",
        "    plt.imshow(image, cmap='gray', origin='upper')\n",
        "    landmarkALL=Xp[error[i],:]\n",
        "    landmark=Xps[error[i],:]\n",
        "    xALL=landmarkALL[::2]\n",
        "    yALL=landmarkALL[1::2]\n",
        "    x=landmark[::2]\n",
        "    y=landmark[1::2]\n",
        "    plt.plot(xALL,yALL,'ob')\n",
        "    plt.plot(x,y,'or')\n",
        "    if  C[error[i]]==0:\n",
        "        plt.title('Image ' + Namesp[error[i]] + ' predicted as neutral')\n",
        "    elif C[error[i]]==1:\n",
        "        plt.title('Image ' + Namesp[error[i]] + ' predicted as happy')\n",
        "    plt.show()\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdSqD9Bw_siM"
      },
      "source": [
        "**Question**: Comment the results. Why did the algorithm make a mistake ? Would you choose other landmarks ? Try at least another combination of landmarks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to4o9FsRPXvu"
      },
      "outputs": [],
      "source": [
        "XXXXXXXXXXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm4sez_p62WX"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Here, we use Nested Cross-Validation for finding the generalization error and the best K value\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnQ87s9_6x3s"
      },
      "outputs": [],
      "source": [
        "# Fitting K-nearest neighbour with Nested Cross-Validation\n",
        " \n",
        "print(\"Fitting K-nearest neighbour with Nested CV\")\n",
        "t0 = time()\n",
        "neigh = KNeighborsClassifier()\n",
        "parameters = {'n_neighbors':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
        "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=666) # we fix the random state to always have the same results if we relaunch the code\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=666)\n",
        "# Nested CV with parameter optimization\n",
        "clf = GridSearchCV(estimator=neigh, param_grid=parameters, cv=inner_cv)\n",
        "nested_CV = cross_validate(estimator=clf, X=XpsGPA, y=np.ravel(Yps), cv=outer_cv,return_train_score=True, return_estimator=True, n_jobs=-1)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\"Average and std Nested Cv train score : {0} +- {1}\".format(nested_CV['train_score'].mean(), nested_CV['train_score'].std() ))\n",
        "print(\"Average and std Nested Cv test score : {0} +- {1}\".format(nested_CV['test_score'].mean(), nested_CV['test_score'].std() ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8vzp82Z-O81"
      },
      "source": [
        "---\n",
        "\n",
        "**Question**: Are Training and Test scores similar ? What does it mean ?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgRMzUCC8-Wz"
      },
      "source": [
        "**Question (OPTIONAL)**: Please propose at least another set of features using landmarks and/or pixel intensities of the images and test its discriminative power"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOJdcSlE8-W0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TP_IntroSupervised_MachineLearning_1part_FEI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}