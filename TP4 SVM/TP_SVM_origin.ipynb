{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDA_obreM3PN"
      },
      "source": [
        "# Skin lesion classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ55RYNTM3PP"
      },
      "source": [
        "**Deadline**: Upload this notebook (rename it as 'TP-SVM-YOUR-SURNAME.ipynb') to Ecampus/Moodle before the deadline. \n",
        "Complete the code where you see XXXXXXXXXXXXXXXXX (mandatory for everybody)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBl0eH4rgj3W"
      },
      "source": [
        "**Context**\n",
        "A skin lesion is defined as a superficial growth or patch of the skin that is visually different and/or has a different texture than its surrounding area. Skin lesions, such as moles or birthmarks, can degenerate and become melanoma, one of the deadliest skin cancer. Its incidence has been increasing during the last decades, especially in the areas mostly populated by white people.\n",
        "\n",
        "The most effective treatment is an early detection followed by surgical excision. This is why several approaches for melanoma detection have been proposed in the last years (non-invasive computer-aided diagnosis (CAD) ).\n",
        "\n",
        "\n",
        "**Goal**\n",
        "The goal of this practical session is to classify images of skin lesions as either benign or melanoma using machine learning algorithms. In order to do that, you will have at your disposal a set of 30 features already extracted from 600 dermoscopic images (both normal skin lesions and melanoma from the ISIC database - https://isic-archive.com/). These features characterize the Asymmetry, the Border irregularity, the Colour and the Dimension of the lesion (the so-called ABCD rule). \n",
        "\n",
        "The features are:\n",
        "- shape asimmetry (f0 and f1)\n",
        "- difference in colors between center and periphery of the image (f2, f3, f4, f27, f28, f29)\n",
        "- geometry (f5, f6, f7)\n",
        "- other features related to eccentricity,entropy, mean, standard deviation and maximum value of each channel in RGB and HSV (f8,...,f24)\n",
        "- asimmetry of color intensity (f25, f26)\n",
        "\n",
        "Features are computed using *manually checked segmentations* and following *Ganster et al. 'Automated melanoma recognition', IEEE TMI, 2001* and *Zortea et al. 'Performance of a dermoscopy-based computer vision system for the diagnosis of pigmented skin lesions compared with visual evaluation by experienced dermatologists', Artificial Intelligence in Medicine, 2014*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP6UCcieM3PT"
      },
      "source": [
        "First load all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggIRZ9_UM3PU"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.io import imread\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import AxesGrid\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import  cross_val_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
        "\n",
        "# Code from scikit-learn\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"black\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFjZc3lXvxLD"
      },
      "source": [
        "Then load the data from my Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcXyy29Qvzcb"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='18hrQVGBCfW7SKTnzmWUONo8iowBsi1DL',\n",
        "dest_path='./data/features.csv')\n",
        "gdd.download_file_from_google_drive(file_id='1iQZdUiuK_FwZ7mik7LB3eN_H_IUc5l7b',\n",
        "dest_path='./data/im/nevus-seg.jpg')\n",
        "gdd.download_file_from_google_drive(file_id='1_TeYzLLDoKbPX4xXAOAM_mQiT2nLHgvp',\n",
        "dest_path='./data/im/nevus.jpg')\n",
        "gdd.download_file_from_google_drive(file_id='1B2Ol92mBcHN6ah3bpoucBbBbHkPMGC8D',\n",
        "dest_path='./data/im/melanoma-seg.jpg')\n",
        "gdd.download_file_from_google_drive(file_id='1yZ46UzGhwO7g5T8397JpewBl6UqgRo5J',\n",
        "dest_path='./data/im/melanoma.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jkc3oIG3skR"
      },
      "source": [
        "Or from yout local computer. Please download the 'data' folder in the same folder as your notebook and do not modifiy it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8F5-rVsTM3PY"
      },
      "source": [
        "Then read the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KszrmyDJM3PZ"
      },
      "source": [
        "## Read data\n",
        "Working_directory=\"./data/\" \n",
        "df = pd.read_csv(Working_directory + 'features.csv') # reading data\n",
        "y = df['Malignant'].values # 1 for Melanoma and 0 for healthy\n",
        "class_names = [\"healthy\",\"melanoma\"]\n",
        "X = df.iloc[:,3:33].values # Features\n",
        "N,M=X.shape\n",
        "print('Number of images: {0}; Number of features per image: {1}'.format(N,M))\n",
        "print('Number of healthy nevus: {0}; Number of melanoma: {1}'.format(N-np.sum(y), np.sum(y)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5Z175vM3Pb"
      },
      "source": [
        "## Plot two examples of nevus and melanoma\n",
        "print('Two examples of healthy nevus and melanoma')\n",
        "nevus = imread(Working_directory + 'im/nevus.jpg')\n",
        "nevus_Segmentation = imread(Working_directory + 'im/nevus-seg.jpg') \n",
        "nevus_Segmentation_boolean = (nevus_Segmentation/255).astype(np.uint8) # To get uint8 (integer numbers)\n",
        "nevus_Segmentation_3D = np.expand_dims(nevus_Segmentation_boolean, axis=2) # To have a binary mask for the three channels (RGB)\n",
        "nevus_mul_mask = (nevus_Segmentation_3D*nevus) # we apply the binary mask to all channels pixel-wise\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12)) # size of the figure\n",
        "grid = AxesGrid(fig, 111,\n",
        "                nrows_ncols = (1, 3),\n",
        "                axes_pad = 0.5) # code to create subplots\n",
        "grid[0].imshow(nevus)\n",
        "grid[0].axis('off')\n",
        "grid[0].set_title('Original image - nevus')\n",
        "grid[1].imshow(nevus_Segmentation)\n",
        "grid[1].axis('off')\n",
        "grid[1].set_title(\"Segmentation mask - nevus\")\n",
        "grid[2].imshow(nevus_mul_mask)\n",
        "grid[2].axis('off')\n",
        "grid[2].set_title(\"Segmented nevus\")\n",
        "\n",
        "###\n",
        "\n",
        "melanoma = imread(Working_directory + 'im/melanoma.jpg')\n",
        "melanoma_Segmentation = imread(Working_directory + 'im/melanoma-seg.jpg') \n",
        "melanoma_Segmentation_boolean = (melanoma_Segmentation/255).astype(np.uint8) # To get uint8 (integer numbers)\n",
        "melanoma_Segmentation_3D = np.expand_dims(melanoma_Segmentation_boolean, axis=2) # To have a binary mask for the three channels (RGB)\n",
        "melanoma_mul_mask = (melanoma_Segmentation_3D*melanoma) # we apply the binary mask to all channels pixel-wise\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12)) # size of the figure\n",
        "grid = AxesGrid(fig, 111,\n",
        "                nrows_ncols = (1, 3),\n",
        "                axes_pad = 0.5) # code to create subplots\n",
        "grid[0].imshow(melanoma)\n",
        "grid[0].axis('off')\n",
        "grid[0].set_title('Original image - melanoma')\n",
        "grid[1].imshow(melanoma_Segmentation)\n",
        "grid[1].axis('off')\n",
        "grid[1].set_title(\"Segmentation mask - melanoma\")\n",
        "grid[2].imshow(melanoma_mul_mask)\n",
        "grid[2].axis('off')\n",
        "grid[2].set_title(\"Segmented melanoma\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4-tYOYOM3Pe"
      },
      "source": [
        "Now, as in the previous practical session you should shuffle the data randomly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXTXPsIIM3Pf"
      },
      "source": [
        "# Shuffle data randomly\n",
        "Xp=XXXXXXXXXXXX\n",
        "yp=XXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "G0mkfbuhM3Pm"
      },
      "source": [
        "We should now test the discriminative power of our features. Fist, let divide the entire data-set into training and test set using the `stratify` option. This will preserve the original proportion between nevus and melanoma also in the training and test set. You can check that from the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-BB5oMcM3Pn"
      },
      "source": [
        "# Create training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xp, yp, test_size=0.3, random_state=42,stratify=yp)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, sharey=True)\n",
        "fig.suptitle('Proportion of samples from each class')\n",
        "axs[0].hist(yp,weights=np.ones_like(yp)/len(yp))\n",
        "axs[0].set_xlabel('Original data-set')\n",
        "axs[1].hist(y_train,weights=np.ones_like(y_train)/len(y_train))\n",
        "axs[1].set_xlabel('Training set')\n",
        "axs[2].hist(y_test,weights=np.ones_like(y_test)/len(y_test))\n",
        "axs[2].set_xlabel('Test set')\n",
        "axs[0].set_ylabel('Proportion')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4SDUC4FM3Ph"
      },
      "source": [
        "As we have already seen, it might be very important to scale the data such that each feature has, for instance, average equal to 0 and unit variance. Which is the right way of doing it when having a training and a test set in your opinion ? Should you use together both training and test set ? (For simplicity's sake, we will restrict here to scaling all features)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uiSSi71M3Pj"
      },
      "source": [
        "# Scale data (each feature will have average equal to 0 and unit variance)\n",
        "XXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOOclOCbznSN"
      },
      "source": [
        "Now, use two simple classification algorithms, for instance LDA and QDA, and look at the confusion matrices. \n",
        "\n",
        "**Question**: Comment the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_ihqCi1M3Pq"
      },
      "source": [
        "# Fitting LDA\n",
        "print(\"Fitting LDA to training set\")\n",
        "t0 = time()\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train_scale, y_train)\n",
        "y_pred = lda.predict(X_test_scale)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='LDA Normalized confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "# Fitting QDA\n",
        "XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecf4abLnM3Ps"
      },
      "source": [
        "The results you obtained are based on a precise subdivision of your data into training and test. This can thus bias your results. Which technique could you use instead ? Test it  with LDA, QDA and K-NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDOcm4HWM3Pt"
      },
      "source": [
        "# Fitting LDA\n",
        "print(\"Fitting LDA\")\n",
        "XXXXXXXXXXXXXXXX\n",
        "\n",
        "# Fitting QDA\n",
        "XXXXXXXXXXXXXXXX\n",
        "\n",
        "# Fitting K-nearest neighbour\n",
        "XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l_wfAsrM3Pw"
      },
      "source": [
        "---\n",
        "When using K-NN, instead than fixing the number of nearest neighbours, we could also estimate the best value using Cross Validation. \n",
        "\n",
        "**Question** Do it and plot the confusion matrix. Do you notice anything strange ? Why in your opinion do you have this kind of result ?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojO6jkeZ9l3Q"
      },
      "source": [
        "# Looking for the best hyperparameters\n",
        "neigh = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "# when using the pipeline, you can print the parameters of the estimator using print(neigh.get_params().keys())`\n",
        "print(neigh.get_params().keys())\n",
        "p_grid_KNN = {'kneighborsclassifier__n_neighbors': [1,2,3,4,5,6,7,8,9,10]}\n",
        "grid_KNN = GridSearchCV(estimator=neigh, param_grid=p_grid_KNN, scoring=\"accuracy\", cv=5)\n",
        "grid_KNN.fit(X_train, y_train)\n",
        "print(\"Best training Score: {}\".format(grid_KNN.best_score_))\n",
        "print(\"Best training params: {}\".format(grid_KNN.best_params_))\n",
        "y_pred = grid_KNN.predict(X_test)\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB6QeHmj-PkN"
      },
      "source": [
        "In order to deal with this problem we have two possible solutions. \n",
        "\n",
        "**First**: Please look at this webpage (https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) and try MORE APPROPRIATE scoring functions than accuracy when looking for the best K value of K-NN (thus within the Cross Validation as before..)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsxD9p1J-sbu"
      },
      "source": [
        "# Looking for the best hyperparameters\n",
        "XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKqhyLTSM3P4"
      },
      "source": [
        "**Second**: when dealing with such a problem (the one you should find !) a possible solution would be to oversample a class (which one in your opinion ?) Please look at this web page for more information (https://imbalanced-learn.org/stable/over_sampling.html) and try at least the ADASYN over-sampling strategy (look at the following code...).\n",
        "\n",
        "NB: if you want to use the naive random oversampling (i.e. randomly sampling with replacement) be careful not to have the same sample both in the training and validation (or test) set during cross-validation (or testing). This would be considered as a data-leakage. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1kyMwyeM3P5"
      },
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from collections import Counter\n",
        "ros = ADASYN(random_state=0)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "E6QK8eGEM3P8"
      },
      "source": [
        "Let's look for the best K in KNN (as before using Cross validation) but this time on the new training set. \n",
        "\n",
        "**Question**: Are the results better ? Do they change now if you modify the scoring function ? Why ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6kM4sKHM3P-"
      },
      "source": [
        "XXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFT0LT7JM3QB"
      },
      "source": [
        "Let's use the techniques seen today: Perceptron and linear SVM. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0g3pszrM3QE"
      },
      "source": [
        "# Fitting Perceptron\n",
        "print(\"Fitting Perceptron\")\n",
        "Perc = make_pipeline(StandardScaler(), Perceptron())\n",
        "Perc_cv = cross_validate(Perc,Xp, yp,cv=5,scoring='accuracy',return_train_score=True)\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Perc_cv['train_score'].mean(), Perc_cv['train_score'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Perc_cv['test_score'].mean(), Perc_cv['test_score'].std() ))\n",
        "\n",
        "\n",
        "# Fitting linear SVM on original data\n",
        "print(\"Fitting Linear SVM\")\n",
        "Lsvm = make_pipeline(StandardScaler(), LinearSVC()) \n",
        "Lsvm_cv = cross_validate(Lsvm,Xp, yp,cv=5,scoring='accuracy',return_train_score=True)\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Lsvm_cv['train_score'].mean(), Lsvm_cv['train_score'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Lsvm_cv['test_score'].mean(), Lsvm_cv['test_score'].std() ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekiuvtrE2Jds"
      },
      "source": [
        "We can easily use different scoring functions within the cross validate function of scikit-learn. Check the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T5mXHJX1lDM"
      },
      "source": [
        "# Fitting Perceptron\n",
        "print(\"Fitting Perceptron\")\n",
        "Perc = make_pipeline(StandardScaler(), Perceptron())\n",
        "Perc_cv = cross_validate(Perc,Xp, yp,cv=5,scoring=('accuracy', 'f1'),return_train_score=True)\n",
        "print(Perc_cv.keys())\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Perc_cv['train_accuracy'].mean(), Perc_cv['train_accuracy'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Perc_cv['test_accuracy'].mean(), Perc_cv['test_accuracy'].std() ))\n",
        "print(\" Average and std TRAIN CV f1 : {0} +- {1}\".format(Perc_cv['train_f1'].mean(), Perc_cv['train_f1'].std() ))\n",
        "print(\" Average and std TEST CV f1 : {0} +- {1}\".format(Perc_cv['test_f1'].mean(), Perc_cv['test_f1'].std() ))\n",
        "\n",
        "\n",
        "# Fitting linear SVM on original data\n",
        "print(\"Fitting Linear SVM\")\n",
        "Lsvm = make_pipeline(StandardScaler(), LinearSVC()) \n",
        "Lsvm_cv = cross_validate(Lsvm,Xp, yp,cv=5,scoring=('accuracy', 'f1'),return_train_score=True)\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Lsvm_cv['train_accuracy'].mean(), Lsvm_cv['train_accuracy'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Lsvm_cv['test_accuracy'].mean(), Lsvm_cv['test_accuracy'].std() ))\n",
        "print(\" Average and std TRAIN CV f1 : {0} +- {1}\".format(Lsvm_cv['train_f1'].mean(), Lsvm_cv['train_f1'].std() ))\n",
        "print(\" Average and std TEST CV f1 : {0} +- {1}\".format(Lsvm_cv['test_f1'].mean(), Lsvm_cv['test_f1'].std() ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DAxlPS7VKz"
      },
      "source": [
        "**Question** Please do the same on the oversampled data and compare the results with the previous ones. Please note that here you should use the ‘make_pipeline‘ function of Imbalanced scikit-learn. You can look here:  [LINK](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.make_pipeline.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8QIk5pU7VU9"
      },
      "source": [
        "from imblearn.pipeline import make_pipeline as make_pipeline2 \n",
        "\n",
        "# Fitting Perceptron\n",
        "print(\"Fitting Perceptron\")\n",
        "Perc = make_pipeline2(ADASYN(random_state=0),StandardScaler(), Perceptron())\n",
        "Perc_cv = cross_validate(Perc,Xp, yp, cv=5,scoring=('accuracy', 'f1'),return_train_score=True)\n",
        "print(Perc_cv.keys())\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Perc_cv['train_accuracy'].mean(), Perc_cv['train_accuracy'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Perc_cv['test_accuracy'].mean(), Perc_cv['test_accuracy'].std() ))\n",
        "print(\" Average and std TRAIN CV f1 : {0} +- {1}\".format(Perc_cv['train_f1'].mean(), Perc_cv['train_f1'].std() ))\n",
        "print(\" Average and std TEST CV f1 : {0} +- {1}\".format(Perc_cv['test_f1'].mean(), Perc_cv['test_f1'].std() ))\n",
        "\n",
        "XXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tomDbS373Dv"
      },
      "source": [
        "We can also ask to save the estimated models at each split (i.e. fold) with the option `return_estimator=True`. Using the perceptron, we will look for the best model using the oversampled training data and check the confusion matrix on the test data. \n",
        "In that case, we will need to first split the data into train/test and then do the oversampling ONLY in the train data. \n",
        "\n",
        "**Question** Do it the same with the linear SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWv94yNA8Tnd"
      },
      "source": [
        "# Fitting Perceptron\n",
        "print(\"Fitting Perceptron\")\n",
        "Perc = make_pipeline2(ADASYN(random_state=0),StandardScaler(), Perceptron())\n",
        "Perc_cv = cross_validate(Perc,X_train, y_train,cv=5,scoring=('accuracy', 'f1'),return_train_score=True,return_estimator=True)\n",
        "print(Perc_cv.keys())\n",
        "print(\" Average and std TRAIN CV accuracy : {0} +- {1}\".format(Perc_cv['train_accuracy'].mean(), Perc_cv['train_accuracy'].std() ))\n",
        "print(\" Average and std TEST CV accuracy : {0} +- {1}\".format(Perc_cv['test_accuracy'].mean(), Perc_cv['test_accuracy'].std() ))\n",
        "print(\" Average and std TRAIN CV f1 : {0} +- {1}\".format(Perc_cv['train_f1'].mean(), Perc_cv['train_f1'].std() ))\n",
        "print(\" Average and std TEST CV f1 : {0} +- {1}\".format(Perc_cv['test_f1'].mean(), Perc_cv['test_f1'].std() ))\n",
        "\n",
        "# Look for the best estimator (the one with the greatest test accuracy)\n",
        "index_best = np.argmax(Perc_cv['test_accuracy'])\n",
        "estimator_best=Perc_cv['estimator'][index_best]\n",
        "y_pred = estimator_best.predict(X_test)\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Fitting linear SVM \n",
        "XXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkGZOucl-t_u"
      },
      "source": [
        "Suppose that there are overlapping classes, we need to set the hyper-parameter C for the SVM model. \n",
        "\n",
        "**Question** Use Cross-Validation on the oversampled data to find the best C value. Plot the confusion matrix using the best estimator (as before)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj6dA32h9NF_"
      },
      "source": [
        "# Looking for the best hyperparameter C \n",
        "Lsvm = make_pipeline2(ADASYN(random_state=0),StandardScaler(), LinearSVC()) \n",
        "p_grid_lsvm = {'linearsvc__C': [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1]}\n",
        "grid_lsvm = GridSearchCV(XXXXXXXXXXXX)\n",
        "XXXXXXXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpIH_H8cM3Qa"
      },
      "source": [
        "Here it is the code for non-linear SVM using radial basis function. We need to tune another hyper-parameter $gamma$. We look for the best $C$ and $gamma$ at the same time.\n",
        "\n",
        "**Question** Use Cross-Validation on the oversampled data to find the best C and $gamma$ value. Plot the confusion matrix using the best estimator (as before)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFecS4EJM3Qb"
      },
      "source": [
        "# Fitting Non-linear SVM\n",
        "print(\"Fitting Non-linear SVM to the training set\")\n",
        "NLsvm = make_pipeline2(ADASYN(random_state=0),StandardScaler(), SVC(kernel='rbf')) \n",
        "p_grid_nlsvm = {'svc__C': [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1],\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]}\n",
        "grid_nlsvm = GridSearchCV(XXXXXXXXXXXXXX)\n",
        "XXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Cr8596_27_"
      },
      "source": [
        "**Question** Use the non-linear SVM with the two strategies seen before (different scoring function and/or oversampled data). Do the results change ? Why in your opinion ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozf6wWBP-bi"
      },
      "source": [
        "**Question** Try to draw a conclusion from the different experiments. Which is the best method ? Which scoring function should you use ? Is it worth it to oversample one of the two classes ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svebl02nFGmt"
      },
      "source": [
        "**OPTIONAL** Another interesting question is: what about the number of features ? Can we reduce the dimensionality ? You could use one of the techniques seen during the previous lectures (i.e. PCA) ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjiAg2siFI4H"
      },
      "source": [
        "# Test PCA with a linear SVM\n",
        "XXXXXXXX\n",
        "\n",
        "Lsvm = make_pipeline2(ADASYN(random_state=0),StandardScaler(), PCA(n_components=0.95), LinearSVC()) \n",
        "p_grid_lsvm = {'linearsvc__C': [1e-3,1e-2,1e-1,1,2,3,4,5,6,7,8,9,1e1]}\n",
        "\n",
        "XXXXXXXXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--RStEOSM3Qw"
      },
      "source": [
        "**OPTIONAL** ... or test the importance of the single features.\n",
        "The more naive technique would be to test each feature independently in a greedy fashion called sequential forward feature selection. Starting from an empty set and a classification model, you will first add the feature that maximizes a certain criterion (i.e. f1 score). Then, you will iterate this process until a chosen stopping criterion by adding at each iteration only the best feature. Each feature can be added of course only once. You could also use the opposite process by removing at each iteraton the least important feature starting from the entire set of features (i.e. sequential backward feature selection). Implement at least one of these ideas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD8T6qaWM3Qx"
      },
      "source": [
        "# Implement forward feature selection and/or backward feature selection\n",
        "# with a linear SVM\n",
        "\n",
        "XXXXXXXXXX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESMevE0MFuKA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}